{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86ce25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nLookBackDays=5\n",
    "nForecastDays=1\n",
    "hoursPerDay = 24\n",
    "nForecastHours = nForecastDays * hoursPerDay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aca84b",
   "metadata": {},
   "source": [
    "# 참고\n",
    "- https://keras.io/examples/timeseries/timeseries_classification_transformer/\n",
    "- 위의 코드는 트랜스포머 모델을 제안한 논문에 나온 모델을 그대로 구현한 것이라고 함\n",
    "- 위의 코드는 시계열 분류 모델을 구현한 것인데, 최종 출력층을 약간 변형하여 시계열을 예측하는 모델로 만들어서 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40b91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 추가 패키지\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233355d4",
   "metadata": {},
   "source": [
    "# 1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0423169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "#pdDataset = pd.read_excel('../1) 한전 전력 전처리/3B)HourlyPower(SeparateDate)(Day1Start)(NoWeekend).xlsx', \n",
    "#                          sheet_name = 'data')\n",
    "pdDataset = pd.read_excel('../1) 한전 전력 전처리/3A)HourlyPower(SeparateDate)(AnyDayStart)(NoWeekend).xlsx', \n",
    "                          sheet_name = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa424a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = pdDataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 ; 불러온 데이터 확인\n",
    "if False:\n",
    "    print(pdDataset.shape)\n",
    "    print(pdDataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d623988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "if False:\n",
    "    print(pdDataset[\"TotalPower(kWh)\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"PeakPower(kW)\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"Date\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"Year\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"Month\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"Day\"][0:5],end=\"\\n\\n\")\n",
    "    print(pdDataset[\"Yoil\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(range(datalen), pdDataset[\"TotalPower(kWh)\"].values)\n",
    "    plt.ylabel('Power consumption')\n",
    "    plt.title(\"Total power use (per hour)\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(range(datalen), pdDataset[\"PeakPower(kW)\"].values, label=\"PEAK power\")\n",
    "    plt.ylabel('Peak power')\n",
    "    #plt.legend()\n",
    "    plt.title(\"Peak power (per hour)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f71968",
   "metadata": {},
   "source": [
    "### 데이터를 하루(24개) 단위로 묶어서 저장하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c619f01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days in total :  181\n"
     ]
    }
   ],
   "source": [
    "# 필요한 상수 정의하기\n",
    "numDaysTotal = int(datalen/hoursPerDay)\n",
    "print(\"Number of days in total : \", numDaysTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ccc9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "perDayTotalPowerList = [] # 하루 24개 데이터를 리스트 형태로 저장(총전력)\n",
    "perDayTotalPower = [] # 하루 24시간 총 전력을 하나의 값으로 해서 저장\n",
    "perDayPeakPowerList = [] # 하루 24개 데이터를 리스트 형태로 저장(peak전력)\n",
    "perDayPeakPower = [] # 하루 중 최대 전력 하나를 골라서 저장\n",
    "perDayDateInfo = [] # 년.월.일 정보를 저장\n",
    "\n",
    "for nthDay in range(numDaysTotal):\n",
    "    currHourTotalPowerList, currHourPeakPowerList = [], []\n",
    "    \n",
    "    currDate = str(pdDataset[\"Year\"][nthDay*hoursPerDay]) + \".\" \\\n",
    "               + str(pdDataset[\"Month\"][nthDay*hoursPerDay]) + \".\" \\\n",
    "               + str(pdDataset[\"Day\"][nthDay*hoursPerDay])\n",
    "    perDayDateInfo.append(currDate)\n",
    "    \n",
    "    for hour in range(hoursPerDay):\n",
    "        index = nthDay*hoursPerDay + hour\n",
    "        currHourTotalPowerList.append(pdDataset[\"TotalPower(kWh)\"][index])\n",
    "        currHourPeakPowerList.append(pdDataset[\"PeakPower(kW)\"][index])\n",
    "   \n",
    "    perDayTotalPowerList.append(currHourTotalPowerList)\n",
    "    perDayTotalPower.append(sum(currHourTotalPowerList))\n",
    "    perDayPeakPowerList.append(currHourPeakPowerList)\n",
    "    perDayPeakPower.append(max(currHourPeakPowerList))\n",
    "    \n",
    "perDayTotalPowerList = np.array(perDayTotalPowerList)\n",
    "perDayTotalPower = np.array(perDayTotalPower)\n",
    "perDayPeakPowerList = np.array(perDayPeakPowerList)\n",
    "perDayPeakPower = np.array(perDayPeakPower)\n",
    "perDayDateInfo = np.array(perDayDateInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7244dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(perDayTotalPowerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f45a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(perDayTotalPower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93429f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(perDayPeakPowerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(perDayPeakPower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b451d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(perDayDateInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2a9ee",
   "metadata": {},
   "source": [
    "# 2 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb393229",
   "metadata": {},
   "source": [
    "## 2.1 outlier 제거, 2.2 누락된 값 복원하기, ...\n",
    "- 별도의 전처리가 필요 없는 것으로 생각되어, 전처리는 하지 않음\n",
    "- 데이터의 수가 충분히 많으므로, 소수의 outlier의 영향이 최소화 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685eefa",
   "metadata": {},
   "source": [
    "## 2.2 전처리된 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5064cc",
   "metadata": {},
   "source": [
    "# 3. Transformer로 예측하기(Univariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a301b",
   "metadata": {},
   "source": [
    "## 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54040b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621783be",
   "metadata": {},
   "source": [
    "## 학습에 사용하기 위해 차원을 고려해서 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc97c1",
   "metadata": {},
   "source": [
    "### 전체 데이터를 학습용, 테스트용으로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607c3c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 171 days out of 181 days\n",
      "Forecast for 10 days out of 181 days.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "학습에 사용할 샘플 수 정하기\n",
    "터미널 출력 결과를 보고 비중(portion)을 적절히 골랐음\n",
    "\"\"\"\n",
    "portion = 0.945\n",
    "howManyDaysToTrain = int(numDaysTotal * portion)\n",
    "\n",
    "if True:\n",
    "    print(\"Train for \" + str(howManyDaysToTrain) \n",
    "          + \" days out of \" + str(numDaysTotal) + \" days\")\n",
    "    print(\"Forecast for %d days out of %d days.\" % (numDaysTotal\n",
    "                                                    - howManyDaysToTrain, numDaysTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536c884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyUtils import split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a1bd7",
   "metadata": {},
   "source": [
    "### 총 전력량 데이터를 split : 시간 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    rawHourlyTotalPower = pdDataset[\"TotalPower(kWh)\"].values\n",
    "    hourlyTotalPowerTrain, hourlyTotalPowerTest \\\n",
    "    = split_dataset(rawHourlyTotalPower, howManyDaysToTrain, hoursPerDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(hourlyTotalPowerTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(hourlyTotalPowerTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83ce92",
   "metadata": {},
   "source": [
    "### 전력 PEAK 데이터를 split : 시간 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637d68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHourlyPeakPower = pdDataset[\"PeakPower(kW)\"].values\n",
    "hourlyPeakPowerTrain, hourlyPeakPowerTest \\\n",
    "= split_dataset(rawHourlyPeakPower, howManyDaysToTrain, hoursPerDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(int(howManyDaysToTrain*0.9)) + \" out of \" + str(howManyDaysToTrain))\n",
    "print(rawHourlyPeakPower.shape)\n",
    "print(hourlyPeakPowerTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e13ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(hourlyPeakPowerTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    print(hourlyPeakPowerTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fdca3",
   "metadata": {},
   "source": [
    "### 총 전력량 데이터를 split ; 일 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa138d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 없음\n",
    "# 어차피, 모든 연속적인 24시간을 단위로 할거라서, 일 단위(1-24시)로 계산한 데이터는 큰 필요가 없고, \n",
    "# 그때그때 직접 계산하여서 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22839b5",
   "metadata": {},
   "source": [
    "### 전력 PEAK 데이터를 split : 일 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912eedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 없음\n",
    "# 어차피, 모든 연속적인 24시간을 단위로 할거라서, 일 단위(1-24시)로 계산한 데이터는 큰 필요가 없고, \n",
    "# 그때그때 직접 계산하여서 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db914d",
   "metadata": {},
   "source": [
    "### 년.월.일 데이터를 split\n",
    "- 이 데이터는 학습에 사용하지는 않음\n",
    "- 추가적인 검증 등의 목적으로 사용할건데, 여튼 다른 데이터와 마찬가지로 split을 해 둬야\n",
    "  다른 데이터와 같은 인덱스를 사용할 수 있으니까 일단은 split을 해 두는 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 없음\n",
    "# 어차피, 모든 연속적인 24시간을 단위로 할거라서, 일 단위(1-24시)로 계산한 데이터는 큰 필요가 없고, \n",
    "# 그때그때 직접 계산하여서 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096adfd",
   "metadata": {},
   "source": [
    "### 학습, 테스트 데이터를 슬라이딩 윈도우 구조에 맞게 정리 (+ 그리고, 과거 몇일간의 데이터를 입력으로 줄 지도 결정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "if False: \n",
    "    d = hourlyTotalPowerTrain\n",
    "    print(d[0])\n",
    "    print(d[1])\n",
    "    print(np.concatenate((d[0],d[1],d[2],d[3]), axis=0))\n",
    "    print(np.concatenate((d[0:4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aca4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyUtils import to_supervisedDaily # 1-24시간 단위로 분할\n",
    "from MyUtils import to_supervisedContinuousHours # 연속된 모든 24시간 단위로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1685a4c",
   "metadata": {},
   "source": [
    "### 학습에 사용할 수 있는 형태로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a819d2b",
   "metadata": {},
   "source": [
    "### (시간 당) 총 전력 사용량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    XHourlyTotalPowerTrain, yHourlyTotalPowerTrain \\\n",
    "    = to_supervisedContinuousHours(hourlyTotalPowerTrain, nLookBackDays, nForecastDays)\n",
    "\n",
    "    # 검증은 1-24시간 단위의 데이터로 할 것임 >> to_supervisedDaily 함수를 사용\n",
    "    XHourlyTotalPowerTest, yHourlyTotalPowerTest \\\n",
    "    = to_supervisedDaily(hourlyTotalPowerTest, nLookBackDays, nForecastDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e252162",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # 샘플 수가 얼마지?\n",
    "    print(XHourlyTotalPowerTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620dcbd",
   "metadata": {},
   "source": [
    "#### 조건부 입력(전력  사용량 총량)을 위해 추가로 데이터 셋 마련하기\n",
    "- 1-24시 단위가 아니다 (y 데이터셋에 들어있는 값의 총합을 직접 구하고, 이것으로 데이터 셋을 마련하자)\n",
    "- 예측할 24시간에 대한 전력 사용량 총합을 미리 계산하고, 이를 조건부 입력으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # 예측할 24시간에 대한 전력 사용량 총합을 미리 계산하고, 이를 조건부 입력으로 사용\n",
    "    XContinuousDailyTotalPowerTrain = []\n",
    "    #print(yHourlyTotalPowerTrain.shape) # (3696, 24, 1)\n",
    "\n",
    "    numSamples = yHourlyTotalPowerTrain.shape[0]\n",
    "    for i in range(numSamples):\n",
    "        sample = yHourlyTotalPowerTrain[i]\n",
    "        XContinuousDailyTotalPowerTrain.append(sum(sample))\n",
    "        if False:\n",
    "            print(sample)\n",
    "            print(sum(sample))\n",
    "            break\n",
    "\n",
    "    XContinuousDailyTotalPowerTrain = np.array(XContinuousDailyTotalPowerTrain)\n",
    "    #print(XContinuousDailyTotalPowerTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    XContinuousDailyTotalPowerTest = []\n",
    "    #print(yHourlyTotalPowerTest.shape) # (5, 24, 1)\n",
    "\n",
    "    numSamples = yHourlyTotalPowerTest.shape[0]\n",
    "    for i in range(numSamples):\n",
    "        sample = yHourlyTotalPowerTest[i]\n",
    "        XContinuousDailyTotalPowerTest.append(sum(sample))\n",
    "\n",
    "    XContinuousDailyTotalPowerTest = np.array(XContinuousDailyTotalPowerTest)\n",
    "    #print(XContinuousDailyTotalPowerTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb61e4f",
   "metadata": {},
   "source": [
    "### (시간 당) PEAK 전력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f16f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "XHourlyPeakPowerTrain, yHourlyPeakPowerTrain \\\n",
    "= to_supervisedContinuousHours(hourlyPeakPowerTrain, nLookBackDays, nForecastDays)\n",
    "\n",
    "# 검증은 1-24시간 단위의 데이터로 할 것임 >> to_supervisedDaily 함수를 사용\n",
    "XHourlyPeakPowerTest, yHourlyPeakPowerTest \\\n",
    "= to_supervisedDaily(hourlyPeakPowerTest, nLookBackDays, nForecastDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7825e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 수가 얼마지?\n",
    "print(XHourlyPeakPowerTrain.shape)\n",
    "print(yHourlyPeakPowerTrain.shape)\n",
    "print(XHourlyPeakPowerTest.shape)\n",
    "print(yHourlyPeakPowerTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5483779",
   "metadata": {},
   "source": [
    "#### 조건부 입력(전력  사용량 총량)을 위해 추가로 데이터 셋 마련하기\n",
    "- 1-24시 단위가 아니다 (y 데이터셋에 들어있는 값의 max를 직접 구하고, 이것으로 데이터 셋을 마련하자)\n",
    "- 예측할 24시간에 대한 전력 사용량 max를 미리 계산하고, 이를 조건부 입력으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 24시간에 대한 전력 peak를 미리 계산하고, 이를 조건부 입력으로 사용\n",
    "XContinuousDailyPeakPowerTrain = []\n",
    "#print(XContinuousDailyPeakPowerTrain.shape)\n",
    "\n",
    "numSamples = yHourlyPeakPowerTrain.shape[0]\n",
    "for i in range(numSamples):\n",
    "    sample = yHourlyPeakPowerTrain[i]\n",
    "    XContinuousDailyPeakPowerTrain.append(max(sample))  # 최대값을 리턴\n",
    "    if i == -1:\n",
    "        print(sample)\n",
    "        print(max(sample))\n",
    "        #break\n",
    "\n",
    "XContinuousDailyPeakPowerTrain = np.array(XContinuousDailyPeakPowerTrain)\n",
    "#print(XContinuousDailyPeakPowerTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d7c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 24시간에 대한 전력 peak를 미리 계산하고, 이를 조건부 입력으로 사용\n",
    "XContinuousDailyPeakPowerTest = []\n",
    "#print(XContinuousDailyPeakPowerTest.shape)\n",
    "\n",
    "numSamples = yHourlyPeakPowerTest.shape[0]\n",
    "for i in range(numSamples):\n",
    "    sample = yHourlyPeakPowerTest[i]\n",
    "    XContinuousDailyPeakPowerTest.append(max(sample))  # 최대값을 리턴\n",
    "    if i == -1:\n",
    "        print(sample)\n",
    "        print(max(sample))\n",
    "        #break\n",
    "\n",
    "XContinuousDailyPeakPowerTest = np.array(XContinuousDailyPeakPowerTest)\n",
    "#print(XContinuousDailyPeakPowerTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743f665",
   "metadata": {},
   "source": [
    "### (일 단위) 총 전력 사용량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속적인 24시간 단위의 데이터 셋 에서는 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cec04e",
   "metadata": {},
   "source": [
    "### (일 단위) PEAK 전력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속적인 24시간 단위의 데이터 셋 에서는 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81987b",
   "metadata": {},
   "source": [
    "### (일 단위) 날짜 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속적인 24시간 단위의 데이터 셋 에서는 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17345d85",
   "metadata": {},
   "source": [
    "## Transformer 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c6a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from MyModels import *\n",
    "#from ForcingMaxUtils import build_transformer_conditionalInput_maxOutput_model_gAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e5974c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_conditionalInput_maxOutput_model_gAvgPooling(\n",
    "    # 전력 PEAK를 조건부 입력으로 제공 + 출력층에서 시계열 데이터의 PEAK를 출력\n",
    "    input_shape, conditional_input_shape, num_outputs,\n",
    "    head_size, num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0, mlp_dropout=0,\n",
    "    ):\n",
    "    \n",
    "    LayerNormEps = 1e-6\n",
    "    \"\"\"\n",
    "    인코더 \n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape, name=\"ts_input\") # 시계열 학습 데이터\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    # PEAK는 최대값을 예측하는 문제니까, max pooling이 더 좋으려나?\n",
    "    #x = layers.GlobalMaxPooling1D(data_format=\"channels_first\")(x)\n",
    "    #x = layers.MaxPooling1D(pool_size=4, strides=1, padding='same', data_format=\"channels_first\")(x)\n",
    "    \n",
    "    # 조건부 입력(일간 총 사용량 예측치) 데이터를 추가로 입력 받음\n",
    "    conditional_inputs = keras.Input(shape=conditional_input_shape, name=\"ts_max_input\")\n",
    "    # 조건부 입력(일간 총 사용량)의 단위가 크고, 다른 특징들은 이미 정규화가 되어있어서\n",
    "    # 조건부 입력을 그대로 사용하면 이로 인한 업데이트가 너무나 과도해 질 수 있음\n",
    "    # 따라서, 조건부 입력에 대해서도 정규화를 실시함\n",
    "    normalized_conditional_inputs \\\n",
    "    = layers.LayerNormalization(epsilon=LayerNormEps)(conditional_inputs)\n",
    "    # 인코더의 최종 출력 + 조건부 입력을 인코더 계층의 최종 출력으로 하고, 디코더로 전달\n",
    "    x = x + normalized_conditional_inputs\n",
    "    \n",
    "    \"\"\"\n",
    "    디코더\n",
    "    \"\"\"\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\",\n",
    "                         kernel_initializer='random_normal',\n",
    "                         bias_initializer='zeros')(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    # 양수만 나와야 하니까, linear 대신 relu\n",
    "    timeseries_outputs = layers.Dense(num_outputs, activation=\"relu\",\n",
    "                                      kernel_initializer='random_normal',\n",
    "                                      bias_initializer='zeros',\n",
    "                                      name='ts_output')(x) \n",
    "    \n",
    "    #시계열 출력을 다시 입력으로 받아서, 출력의 element-wise max을 계산\n",
    "    max_outputs = layers.Lambda(lambda v: K.max(v), \n",
    "                                output_shape=(1,1),\n",
    "                                name=\"ts_max\")(timeseries_outputs)\n",
    "    # 최종 모델을 리턴\n",
    "    return keras.Model(inputs = [inputs, conditional_inputs], \n",
    "                       outputs = [timeseries_outputs, max_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f687aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyMetrics import mape, smape, rmse, mae, coeff_determination\n",
    "import os\n",
    "from MyUtils import plotTrainingProgress\n",
    "from ForcingMaxUtils import test_predict_mergedInput_mergedOutput_forcingMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb3167",
   "metadata": {},
   "source": [
    "## PEAK 전력 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9eb9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" # first gpu for Case 1 code\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # first gpu for Case 1 code\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # second gpu for Case 2 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f507f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoutRate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f516a2",
   "metadata": {},
   "source": [
    "### PEAK : Case 2 (Trial 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1e0f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_peakpower_case2_1 = build_transformer_conditionalInput_maxOutput_model_gAvgPooling(\n",
    "    input_shape = XHourlyPeakPowerTrain.shape[1:],\n",
    "    conditional_input_shape = XContinuousDailyPeakPowerTrain.shape[1:],\n",
    "    num_outputs = nForecastHours,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4, # 8 : 성능이 오히려 떨어짐\n",
    "    num_transformer_blocks=6,\n",
    "    #mlp_units=[128, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_units=[512, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_dropout=dropoutRate, # 0.4\n",
    "    dropout=dropoutRate) # 0.25\n",
    "\"\"\"\n",
    "시계열 max가  예측 peak와 같아지는 것을 강제하는 가중치\n",
    "peak 예측도 중요하고, 시계열 예측도 중요(몇시에 발생하는지)하므로\n",
    "peak 예측에 대한 가중치를 높여나가면서 실험 함\n",
    "\"\"\"\n",
    "ts_max_weight = 0.1\n",
    "lossWeight = {\"ts_output\":1.0-ts_max_weight,\"ts_max\":ts_max_weight}\n",
    "\n",
    "# ts : time-series\n",
    "# ts_max의 영향을 줄이기 위해서 가중치 작게 설정했고, mae를 사용함\n",
    "# => mse로 변경\n",
    "# Adam + decay를 사용할거라면, 초기 lr은 큰 값으로 설정해도 되겠다.\n",
    "model_peakpower_case2_1.compile(loss = {\"ts_output\" : 'mse', \"ts_max\" : 'mae'},\n",
    "                              optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                              metrics = {\"ts_output\":mae,\"ts_max\":mae},\n",
    "                              loss_weights = lossWeight)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)]\n",
    "\n",
    "training_history_peakpower_case2_1 = \\\n",
    "model_peakpower_case2_1.fit(\n",
    "    x = {\"ts_input\" : XHourlyPeakPowerTrain, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTrain},\n",
    "    y = {\"ts_output\" : yHourlyPeakPowerTrain, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTrain},    \n",
    "    validation_data=(\n",
    "        {\"ts_input\" : XHourlyPeakPowerTest, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTest},\n",
    "        {\"ts_output\" : yHourlyPeakPowerTest, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTest},        \n",
    "    ),\n",
    "    epochs = 100,  # 어차피 early stopping이 적용될거라 epoch 커도 ok\n",
    "    batch_size = 32,  # 64보다, 128일때 속도가 더 빠르다...? 그런데, 32가 가장 일반적으로 사용하는 숫자라고 함\n",
    "    callbacks = callbacks,\n",
    "    verbose = 2,\n",
    "    shuffle = True) # True로 하더라도, 검증 데이터는 섞이지 않음 (True가 결과가 더 좋음)\n",
    "\n",
    "plotTrainingProgress(training_history=training_history_peakpower_case2_1, \n",
    "                     title=\"Case 2 ; peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 예측하기 (총전력)\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "test_predict_mergedInput_mergedOutput_forcingMax(model_peakpower_case2_1, \n",
    "             [XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             \"Case 2 : peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "model_peakpower_case2_1.evaluate([XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73ddde",
   "metadata": {},
   "source": [
    "### PEAK : Case 2 (Trial 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0d48d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_peakpower_case2_2 = build_transformer_conditionalInput_maxOutput_model_gAvgPooling(\n",
    "    input_shape = XHourlyPeakPowerTrain.shape[1:],\n",
    "    conditional_input_shape = XContinuousDailyPeakPowerTrain.shape[1:],\n",
    "    num_outputs = nForecastHours,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4, # 8 : 성능이 오히려 떨어짐\n",
    "    num_transformer_blocks=6,\n",
    "    #mlp_units=[128, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_units=[512, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_dropout=dropoutRate, # 0.4\n",
    "    dropout=dropoutRate) # 0.25\n",
    "\"\"\"\n",
    "시계열 max가  예측 peak와 같아지는 것을 강제하는 가중치\n",
    "peak 예측도 중요하고, 시계열 예측도 중요(몇시에 발생하는지)하므로\n",
    "peak 예측에 대한 가중치를 높여나가면서 실험 함\n",
    "\"\"\"\n",
    "ts_max_weight = 0.1\n",
    "lossWeight = {\"ts_output\":1.0-ts_max_weight,\"ts_max\":ts_max_weight}\n",
    "\n",
    "# ts : time-series\n",
    "# ts_max의 영향을 줄이기 위해서 가중치 작게 설정했고, mae를 사용함\n",
    "# => mse로 변경\n",
    "# Adam + decay를 사용할거라면, 초기 lr은 큰 값으로 설정해도 되겠다.\n",
    "model_peakpower_case2_2.compile(loss = {\"ts_output\" : 'mse', \"ts_max\" : 'mae'},\n",
    "                              optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                              metrics = {\"ts_output\":mae,\"ts_max\":mae},\n",
    "                              loss_weights = lossWeight)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)]\n",
    "\n",
    "training_history_peakpower_case2_2 = \\\n",
    "model_peakpower_case2_2.fit(\n",
    "    x = {\"ts_input\" : XHourlyPeakPowerTrain, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTrain},\n",
    "    y = {\"ts_output\" : yHourlyPeakPowerTrain, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTrain},    \n",
    "    validation_data=(\n",
    "        {\"ts_input\" : XHourlyPeakPowerTest, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTest},\n",
    "        {\"ts_output\" : yHourlyPeakPowerTest, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTest},        \n",
    "    ),\n",
    "    epochs = 100,  # 어차피 early stopping이 적용될거라 epoch 커도 ok\n",
    "    batch_size = 32,  # 64보다, 128일때 속도가 더 빠르다...? 그런데, 32가 가장 일반적으로 사용하는 숫자라고 함\n",
    "    callbacks = callbacks,\n",
    "    verbose = 2,\n",
    "    shuffle = True) # True로 하더라도, 검증 데이터는 섞이지 않음 (True가 결과가 더 좋음)\n",
    "\n",
    "plotTrainingProgress(training_history=training_history_peakpower_case2_2, \n",
    "                     title=\"Case 2 ; peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 예측하기 (총전력)\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "test_predict_mergedInput_mergedOutput_forcingMax(model_peakpower_case2_2, \n",
    "             [XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             \"Case 2 : peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "model_peakpower_case2_2.evaluate([XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39802401",
   "metadata": {},
   "source": [
    "### PEAK : Case 2 (Trial 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118a77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_peakpower_case2_3 = build_transformer_conditionalInput_maxOutput_model_gAvgPooling(\n",
    "    input_shape = XHourlyPeakPowerTrain.shape[1:],\n",
    "    conditional_input_shape = XContinuousDailyPeakPowerTrain.shape[1:],\n",
    "    num_outputs = nForecastHours,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4, # 8 : 성능이 오히려 떨어짐\n",
    "    num_transformer_blocks=6,\n",
    "    #mlp_units=[128, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_units=[512, 256, 64], # 문제의 복잡도 증가로 인해, 디코더 쪽에서 MLP 계층을 늘렸음\n",
    "    mlp_dropout=dropoutRate, # 0.4\n",
    "    dropout=dropoutRate) # 0.25\n",
    "\"\"\"\n",
    "시계열 max가  예측 peak와 같아지는 것을 강제하는 가중치\n",
    "peak 예측도 중요하고, 시계열 예측도 중요(몇시에 발생하는지)하므로\n",
    "peak 예측에 대한 가중치를 높여나가면서 실험 함\n",
    "\"\"\"\n",
    "ts_max_weight = 0.1\n",
    "lossWeight = {\"ts_output\":1.0-ts_max_weight,\"ts_max\":ts_max_weight}\n",
    "\n",
    "# ts : time-series\n",
    "# ts_max의 영향을 줄이기 위해서 가중치 작게 설정했고, mae를 사용함\n",
    "# => mse로 변경\n",
    "# Adam + decay를 사용할거라면, 초기 lr은 큰 값으로 설정해도 되겠다.\n",
    "model_peakpower_case2_3.compile(loss = {\"ts_output\" : 'mse', \"ts_max\" : 'mae'},\n",
    "                              optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                              metrics = {\"ts_output\":mae,\"ts_max\":mae},\n",
    "                              loss_weights = lossWeight)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)]\n",
    "\n",
    "training_history_peakpower_case2_3 = \\\n",
    "model_peakpower_case2_3.fit(\n",
    "    x = {\"ts_input\" : XHourlyPeakPowerTrain, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTrain},\n",
    "    y = {\"ts_output\" : yHourlyPeakPowerTrain, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTrain},    \n",
    "    validation_data=(\n",
    "        {\"ts_input\" : XHourlyPeakPowerTest, \n",
    "         \"ts_max_input\" : XContinuousDailyPeakPowerTest},\n",
    "        {\"ts_output\" : yHourlyPeakPowerTest, \n",
    "         \"ts_max\" : XContinuousDailyPeakPowerTest},        \n",
    "    ),\n",
    "    epochs = 100,  # 어차피 early stopping이 적용될거라 epoch 커도 ok\n",
    "    batch_size = 32,  # 64보다, 128일때 속도가 더 빠르다...? 그런데, 32가 가장 일반적으로 사용하는 숫자라고 함\n",
    "    callbacks = callbacks,\n",
    "    verbose = 2,\n",
    "    shuffle = True) # True로 하더라도, 검증 데이터는 섞이지 않음 (True가 결과가 더 좋음)\n",
    "\n",
    "plotTrainingProgress(training_history=training_history_peakpower_case2_3, \n",
    "                     title=\"Case 2 ; peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 예측하기 (총전력)\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "test_predict_mergedInput_mergedOutput_forcingMax(model_peakpower_case2_3, \n",
    "             [XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             \"Case 2 : peak power (%d LookBack)\"%(nLookBackDays))\n",
    "\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "model_peakpower_case2_3.evaluate([XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9b5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_mergedInput_mergedOutput_forcingMax_multiplemodels(model1, model2, model3, Xmerged, ymerged, title, _ylim=None):\n",
    "    # X 데이터 분리\n",
    "    X = Xmerged[0]\n",
    "    conditionalX = Xmerged[1]\n",
    "    # y 데이터 분리\n",
    "    y = ymerged[0]\n",
    "    maxy = ymerged[1]\n",
    "\n",
    "    ts_pred = [] # 시계열 예측값을 저장할 리스트\n",
    "    actual = y.reshape(y.shape[0] * y.shape[1]) # 시계열 정답을 저장할 리스트\n",
    "    \n",
    "    ts_max_pred = [] # 24시간 예측 단위로, 예측으로 생성한 시계열 데이터의 max 저장할 리스트\n",
    "    max_y_values = [] # 24시간 예측 단위로, 정답에 해당하는 시계열 데이터의 max 저장할 리스트\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        x_sample1 = X[i].reshape(1, len(X[i]), 1)\n",
    "        x_sample2 = conditionalX[i].reshape(1, len(conditionalX[i]), 1)\n",
    "        \n",
    "        [y_hat1, y_hat_max1] = model1.predict([x_sample1, x_sample2])\n",
    "        [y_hat2, y_hat_max2] = model2.predict([x_sample1, x_sample2])\n",
    "        [y_hat3, y_hat_max3] = model3.predict([x_sample1, x_sample2])\n",
    "            \n",
    "        y_hat_values1 = y_hat1[0].reshape(len(y_hat1[0]),).tolist()\n",
    "        y_hat_values2 = y_hat2[0].reshape(len(y_hat2[0]),).tolist()\n",
    "        y_hat_values3 = y_hat3[0].reshape(len(y_hat3[0]),).tolist()\n",
    "        \n",
    "        y_hat_values = []\n",
    "        for j in range(len(y_hat_values1)):\n",
    "            y_hat_values.append(max(y_hat_values1[j],y_hat_values2[j],y_hat_values3[j]))\n",
    "\n",
    "        if len(ts_pred) == 0:\n",
    "            ts_pred = y_hat_values\n",
    "        else:\n",
    "            ts_pred = ts_pred + y_hat_values\n",
    "            \n",
    "        ts_max_pred.append(max(y_hat_max1,y_hat_max2,y_hat_max3))\n",
    "        max_y_values.append(maxy[i][0])\n",
    "            \n",
    "    # 시계열 데이터 예측값을 plot\n",
    "    print(\"TimeSeries MAE : %d\"%(int(mae(actual, ts_pred))))\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    plt.figure()\n",
    "    plt.plot(actual, label='actual')\n",
    "    plt.plot(ts_pred, label='forecast')\n",
    "    plt.title(title) \n",
    "    plt.legend()\n",
    "    plt.xlabel('hours')\n",
    "    if _ylim is not None:\n",
    "        plt.ylim(_ylim)\n",
    "    plt.show()\n",
    "        \n",
    "    # 24시간 예측 단위로, 시계열 데이터의 총합을 plot\n",
    "    print(\"TimeSeriesSum MAE : %d\"%(int(mae(np.array(max_y_values), np.array(ts_max_pred)))))\n",
    "    #print(sum_y_values)\n",
    "    #print(ts_sum_pred)\n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(len(max_y_values))-0.1, max_y_values, width=0.3, label='actual')\n",
    "    plt.bar(np.arange(len(ts_max_pred))+0.1, ts_max_pred, width=0.3, label='forecast')\n",
    "    plt.legend()\n",
    "    plt.title(\"Comparison: daily power max\")\n",
    "    plt.xlabel('days')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기 (총전력)\n",
    "# 평가는 1-24시 단위로 자른 데이터로...\n",
    "test_predict_mergedInput_mergedOutput_forcingMax_multiplemodels(model_peakpower_case2_1, model_peakpower_case2_2, model_peakpower_case2_3, \n",
    "             [XHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             [yHourlyPeakPowerTest,XContinuousDailyPeakPowerTest], \n",
    "             \"Case 2 : peak power (%d LookBack)\"%(nLookBackDays))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
